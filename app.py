import json, torch, numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import streamlit as st
import pandas as pd

st.set_page_config(
    page_title="Thai News Classification",
    page_icon="üì∞",
    layout="centered"
)

MODEL_DIR = "wcberta-prachathai67k-best"  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà save_pretrained ‡πÑ‡∏ß‡πâ
MAX_LEN   = 512
THRESH    = 0.5   

tok = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).eval()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)
model.to(device)


with open(f"{MODEL_DIR}/label_names.json", encoding="utf-8") as f:
    LABELS = json.load(f)


def predict_with_probs(texts: list[str], threshold :float = THRESH , top_k:int = None):
    """
    ‡∏Ñ‡∏∑‡∏ô:
      - probs_sorted: ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™ + prob ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢
      - chosen: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà ‚Äú‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‚Äù (threshold ‡∏´‡∏£‡∏∑‡∏≠ top_k)
    """
    enc = tok(texts, return_tensors="pt", truncation=True, max_length=MAX_LEN, padding=True)
    enc = {k: v.to(device) for k, v in enc.items()}

    sigmoid = torch.nn.Sigmoid()
    with torch.no_grad():
        logits = model(**enc).logits
        probs = sigmoid(logits).cpu().numpy()  # (B, C)

    results = []
    for i, text in enumerate(texts):
        p = probs[i]                                 # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™
        order = np.argsort(p)[::-1]                  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏°‡∏≤‡∏Å‚Üí‡∏ô‡πâ‡∏≠‡∏¢
        probs_sorted = [(LABELS[j], float(p[j])) for j in order]

        if top_k and top_k > 0:
            chosen = [LABELS[j] for j in order[:top_k]]
        else:
            chosen = []
            for name , prob in probs_sorted:
                
                if prob >= threshold:
                    chosen.append(name)
                else:
                    break
            

        results.append({
            "text": text,
            "probs_sorted": probs_sorted,  # ‡∏î‡∏π‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏î‡πâ
            "chosen": chosen               # ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™
        })
    return results

st.title("üì∞ Thai News Classification")
st.markdown("‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πà‡∏≤‡∏ß‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• `wcberta-prachathai67k-best`")

st.write("‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)")
input_texts = st.text_area("‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 512 ‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î):", height=200, placeholder="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏Å‡∏£‡∏°‡∏≠‡∏∏‡∏ï‡∏∏‡∏Ø ‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏ó‡∏¢‡πÄ‡∏à‡∏≠‡∏ù‡∏ô‡∏ñ‡∏•‡πà‡∏°...")

if st.button("üß† ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•"):
    if not input_texts.strip():
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•")
    else:
        texts = [text.strip() for text in input_texts.split('\n') if text.strip()]
        
        valid_texts = []
        for i, text in enumerate(texts):
            if len(text.split()) > 512:
                st.error(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà {i+1} ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô 512 ‡∏Ñ‡∏≥: '{text[:50]}...'")
            else:
                valid_texts.append(text)

        if valid_texts:
            with st.spinner("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°..."):
                results = predict_with_probs(valid_texts, threshold=None, top_k=3)
                
                st.success("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                
                st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:")
                for result in results:
                    with st.container(border=True):
                        st.markdown(f"**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:** {result['text']}")
                        
                        tags = ' '.join([f"`{cat}`" for cat in result['chosen']])
                        st.markdown(f"**‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:** {tags}")

                        with st.expander("‡∏î‡∏π‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
                            df = pd.DataFrame(result['probs_sorted'], columns=['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô'])
                            st.dataframe(df, use_container_width=True)
                        st.markdown(f"**‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:** {tags}")

                        with st.expander("‡∏î‡∏π‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
                            df = pd.DataFrame(result['probs_sorted'], columns=['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô'])
                            st.dataframe(df, use_container_width=True)


